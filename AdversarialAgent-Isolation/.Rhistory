pMin <- min(summary$coefficients[, 4])
rSqrAdj <- summary$adj.r.squared
sigma <- summary$sigma
bestFit$model
summary(bestFit)
names(summary(bestFit))
summary(bestFit)$call
summary(bestFit)$terms
summary(bestFit)$call
summary$coef
myModel <- lm(mpg ~ wt + qsec + am + wt:am, data = mtcars)
summary <- summary(myModel)
summary$coef
myModel <- lm(mpg ~ wt + qsec + am + wt:am, data = mtcars)
summary <- summary(myModel)
e <- resid(myModel)
plot(e)
plot(e, myModel$fit)
plot(myModel$fit ~ e)
plot(myModel$fit, e)
plot(myModel)
plot(x = myModel$fit, y = e)
abline(myModel, lwd = 2)
abline(myModel)
x <- diamond$carat
y <- diamond$price
n <- nrow(diamond)
fit <- lm(y ~ x, data = diamond)
yhat <- predict(fit)
plot(x = x, y = y,
xlab = "Mass (Carat)",
ylab = "Price (SGD)",
bg = "lightblue", col = "black",
cex = 1.1, pch = 21, frame = FALSE)
abline(fit, lwd = 2)
for(i in 1:n)
{
lines(c(x[i], x[i]), c(y[i], yhat[i]), col = "red", lwd = 2)
}
myModel
myModel <- lm(mpg ~ wt + qsec + am + wt:am, data = mtcars)
plot(myModel)
names(myModel)
names(myModel$residuals)
plot(myModel$residuals)
abline(myModel$fit)
abline(myModel)
?plot
dfbetas(myModel)
plot(myModel)
print(plot(myModel))
qplot(myModel)
anova(myModel)
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(fit)
library(DAAG)
install.packages("DAAG")
library(DAAG)
cv.lm(df = mtcars, myModel, m = 3)
layout(matrix(c(1,1))
)
cv.lm(df = mtcars, myModel, m = 3)
?cv.lm
cv.lm(df = mtcars, myModel, m = 3, plotit = "Residuals")
?cv.lm
cv.lm(df = mtcars, myModel, m = 3, plotit = "Residual")
cv.lm(df = mtcars, myModel, m = 3)
bestFit <- step(fitAll, k=log(nrow(mtcars)))
summary$call
summary$call[1]
summary$call[2]
summary$call[3]
summary$call.model
summary$model
bestFit$model
as.character(summary$call)
as.character(summary$call[2])
itAll <- lm(mpg ~ ., data=mtcars)
summary <- summary(fitAll)
pMax <- max(summary$coefficients[, 4])
pMin <- min(summary$coefficients[, 4])
rSqrAdj <- summary$adj.r.squared
sigma <- summary$sigma
bestFit <- step(fitAll, k=log(nrow(mtcars)))
?step
bestFit <- step(fitAll, k=log(nrow(mtcars)), trace = 0)
bestFit <- step(fitAll, k=log(nrow(mtcars)), trace = 0)
summary <- summary(bestFit)
summary$coefficients
myModel <- lm(mpg ~ wt + qsec + am + wt:am, data = mtcars)
summary <- summary(myModel)
pMax <- max(summary$coefficients[-1, 4])
pMin <- min(summary$coefficients[-1, 4])
rSqrAdj <- summary$adj.r.squared
sigma <- summary$sigma
summary$coef
summary$coef[1, 4]
summary$coef[4, 1]
?cv.lm
cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"))
cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"), printit = FALSE)
?cv.lm
cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"), printit=F)
cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"), printit=F, trace = 0)
result <- cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"), printit=F, trace = 0)
result <- cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"), printit=F)
result <- cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"), printit=F, warning.suppress = T)
result <- cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"), printit=F, warning = F)
res <- cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"))
res <- cv.lm(df = mtcars, myModel, m = 3, plotit = c("Observed","Residual"), printit = F)
layout(matrix(c(1,2),2,2))
suppressWarnings(cv.lm(df = mtcars, myModel, m = 3, printit = F))
suppressWarnings(cv.lm(df = mtcars, myModel, m = 3, plotit = "Residual",
printit = F))
siwrl()
swirl()
library(swirl)
swirl()
install_from_swirl("Regression Models")
swirl()
fit <- lm(child ~ parent, data = galton)
summary(fit)
mean(r$residuals)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
fit$coef
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs-rhs
all.equal(lsh, rhs)
all.equal(lhs, rhs)
varChild <- var(galton$Child)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- est(ols.slope, ols.ic)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, varRes + varEst)
efit < lm(accel ~ mag _ dist, data = attenu)
efit < lm(accel ~ mag + dist, data = attenu)
efit <- lm(accel ~ mag + dist, data = attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
layout(matrix(1,1))
install.packages("carot")
install.packages("caret")
upgrade.packages()
package.upgrade()
packages.upgrade()
data(spam)
data(Spam)
library(caret)
library(kernlab)
data("spam")
head(spam)
?createDataPartition
inTrain <- createDataPartition(y = spam$type, p = 0.75, list = FALSE)
training <- spam[inTrain, ]
test <- spam[-inTrain, ]
dim(training)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
head(predictors)
head(desease)
head(diagnosis)
diagnosis
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
names(training)
hist(training$Superplasticizer)
hist(log(training$Superplasticizer)
)
hist(training$Superplasticizer)
summary(training$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
subtrain <- training[, c(58:69)]
head(subtrain)
?preProcess
p <- preProcess(subtrain, method = "pca")
p
p <- preProcess(subtrain, method = "pca", thresh = 0.9)
p
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
subtrain <- training[, c(58:69)]
names(subtrain)
head(training)
subtrain <- training[, c(1, 58:69)]
head(subtrain)
p <- preProcess(subtrain, method = "pca", thresh = 0.8)
p <- preProcess(subtrain[, -c(1)], method = "pca", thresh = 0.8)
fi <- glm(diagnosis ~ ., data = training)
p <- preProcess(subtrain, method = "knnImpute",)
p <- preProcess(subtrain, method = "knnImpute")
training <- training[-is.na(training$diagnosis ), ]
fi <- glm(diagnosis ~ ., data = training)
g <- ggplot(data = diamond, aes(x = carat, y = price))
g <- g + xlab("Mass (carats)") + ylab("Price (SGD)")
g <- g + geom_point(size = 6, colour = "black", alpha = 0.2)
g <- g + geom_point(size = 5, colour = "blue", alpha = 0.2)
g <- g + geom_smooth(method = "lm", colour = "black")
g
fit <- lm(price ~ carat, data = diamond)
summary(fit)
coef(fit)
# fit around the mean
fit2 <- lm(price ~ I(carat - mean(carat)), data = diamond)
summary(fit2)
coef(fit2)
# fitting for 1/10th of the carat
# fit around the mean
fit3 <- lm(price ~ I(carat * 10), data = diamond)
summary(fit3)
coef(fit3)
# predicting price of new diamonds
new_diamonds <- c(0.16, 0.27, 0.34)
predict(fit, newdata = data.frame(carat = new_diamonds))
library(UsingR)
library(ggplot2)
library(class)
data(diamond)
g <- ggplot(data = diamond, aes(x = carat, y = price))
g <- g + xlab("Mass (carats)") + ylab("Price (SGD)")
g <- g + geom_point(size = 6, colour = "black", alpha = 0.2)
g <- g + geom_point(size = 5, colour = "blue", alpha = 0.2)
g <- g + geom_smooth(method = "lm", colour = "black")
g
fit <- lm(price ~ carat, data = diamond)
summary(fit)
coef(fit)
# fit around the mean
fit2 <- lm(price ~ I(carat - mean(carat)), data = diamond)
summary(fit2)
coef(fit2)
# fitting for 1/10th of the carat
# fit around the mean
fit3 <- lm(price ~ I(carat * 10), data = diamond)
summary(fit3)
coef(fit3)
# predicting price of new diamonds
new_diamonds <- c(0.16, 0.27, 0.34)
predict(fit, newdata = data.frame(carat = new_diamonds))
x <- diamond$carat
y <- diamond$price
n <- nrow(diamond)
fit <- lm(y ~ x)
# find residual
e <- resid(fit)
yhat <- predict(fit)
max(abs(e - (y - yhat)))
x <- diamond$carat
y <- diamond$price
n <- nrow(diamond)
fit <- lm(y ~ x, data = diamond)
yhat <- predict(fit)
plot(x = x, y = y,
xlab = "Mass (Carat)",
ylab = "Price (SGD)",
bg = "lightblue", col = "black",
cex = 1.1, pch = 21, frame = FALSE)
abline(fit, lwd = 2)
for(i in 1:n)
{
lines(c(x[i], x[i]), c(y[i], yhat[i]), col = "red", lwd = 2)
}
x <- diamond$carat
y <- diamond$price
n <- nrow(diamond)
fit <- lm(y ~ x, data = diamond)
e <- resid(fit)
yhat <- predict(fit)
plot(x = x, y = e,
xlab = "Mass (Carat)",
ylab = "Residual (SGD)",
bg = "lightblue", col = "black",
cex = 1.1, pch = 21, frame = FALSE)
abline(h = 0, lwd = 2)
for(i in 1:n)
{
lines(c(x[i], x[i]), c(e[i], 0), col = "red", lwd = 2)
}
set.seed(111)
x <- runif(100, -3, 3)
y <- x + sin(x) + rnorm(100, sd =0.2)
fit <- lm(y ~ x)
e <- resid(fit)
yhat <- predict(fit)
g <- ggplot(data = data.frame(x = x, y = y), aes(x = x, y = y))
g <- g + geom_smooth(method = "lm", colour = "black")
g <- g + geom_point(size = 7, colour = "black", alpha = 0.4)
g <- g + geom_point(size = 5, colour = "red", alpha = 0.4)
g
# check residual pattern which should capure the sin(x) pattern since
# linear model has missed the sin(x) pattern, assuming a linear relationship
g2 <- ggplot(data = data.frame(x = x, y = e), aes(x= x, y = y))
g2 <- g2 + geom_hline(yintercept = 0, size = 2)
g2 <- g2 + geom_point(size = 7, colour = "black", alpha = 0.4)
g2 <- g2 + geom_point(size = 5, colour = "red", alpha = 0.4)
g2 <- g2 + xlab("X") + ylab("Residual")
g2
set.seed(111)
x <- runif(100, 0, 6)
y <- x  + rnorm(100, mean = 0, sd =0.001 *x)
fit <- lm(y ~ x)
e <- resid(fit)
yhat <- predict(fit)
g <- ggplot(data = data.frame(x = x, y = y), aes(x = x, y = y))
g <- g + geom_smooth(method = "lm", colour = "black")
g <- g + geom_point(size = 7, colour = "black", alpha = 0.4)
g <- g + geom_point(size = 5, colour = "red", alpha = 0.4)
g
# check residual pattern which should capure the sin(x) pattern since
# linear model has missed the sin(x) pattern, assuming a linear relationship
g2 <- ggplot(data = data.frame(x = x, y = e), aes(x= x, y = y))
g2 <- g2 + geom_hline(yintercept = 0, size = 2)
g2 <- g2 + geom_point(size = 7, colour = "black", alpha = 0.4)
g2 <- g2 + geom_point(size = 5, colour = "red", alpha = 0.4)
g2 <- g2 + xlab("X") + ylab("Residual")
g2
set.seed(111)
x <- diamond$carat
y <- diamond$price
fit <- lm(y ~ x)
e <- resid(fit)
yhat <- predict(fit)
g <- ggplot(data = data.frame(x = x, y = y), aes(x = x, y = y))
g <- g + geom_smooth(method = "lm", colour = "black")
g <- g + geom_point(size = 7, colour = "black", alpha = 0.4)
g <- g + geom_point(size = 5, colour = "red", alpha = 0.4)
g
# residual plot
g2 <- ggplot(data = data.frame(x = x, y = e), aes(x= x, y = y))
g2 <- g2 + geom_hline(yintercept = 0, size = 2)
g2 <- g2 + geom_point(size = 7, colour = "black", alpha = 0.4)
g2 <- g2 + geom_point(size = 5, colour = "red", alpha = 0.4)
g2 <- g2 + xlab("X") + ylab("Residual")
g2
# residual variability
diamond$e <- e
# price variability
e1 <- resid(lm(price ~ 1, data = diamond))
e2 <- c(e1, e)
fit2 <- factor(c(rep("Itc", nrow(diamond)),
rep("Itc, slope", nrow(diamond))))
g3 <- ggplot(data.frame(e = e2, fit = fit2), aes(x = fit, y = e, fill = fit))
g3 <- g3 + geom_dotplot(binaxis = "y", size =2, stackdir = "center",
binwidth = 30, colour = "red")
g3 <- g3 + xlab("Fitting approach") + ylab("Residual Price")
g3
x <- diamond$carat
y <- diamond$price
n <- nrow(diamond)
Beta1 <- cor(y, x) * sd(y) / sd(x)
Beta0 <- mean(y) - Beta1 * mean(x)
e <- y - Beta0 - Beta1 * x
sigma <- sqrt(sum(e ^ 2)) / (n-2)
ssx <- sum((x - mean(x)) ^ 2)
seBeta0 <- (1 /n + mean(x) ^2 / ssx) ^ 0.5 * sigma
seBeta1 <- sigma / sqrt(ssx)
tBeta0 <- Beta0 / seBeta0
tBeta1 <- Beta1 / seBeta1
pBeta0 <- 2 * pt(abs(tBeta0), df = n-2, lower.tail = FALSE)
pBeta1 <- 2 * pt(abs(tBeta1), df = n-2, lower.tail = FALSE)
coefTable <- rbind(c(Beta0, seBeta0, tBeta0, pBeta0),
c(Beta1, seBeta1, tBeta1, pBeta1))
colnames(coefTable) <- c("Estimate", "Standard Error", "t-value", "P ( > |t| )")
rownames(coefTable) <- c("Intercept", "x")
print("Calculated Parameters")
coefTable
# lm does these calculations and give the summary
fit <- lm(y ~ x)
print("Linear Regression Parameters")
summary(fit)$coefficients
# confidence interval
print("Confidence Intervals")
sumCoeff <- summary(fit)$coefficients
sumCoeff[1, 1] + c(-1, 1) * qt(0.975, df = fit$df) * sumCoeff[1, 2]
# show unit as increase in per 0.1 carat mass
(sumCoeff[2, 1] + c(-1, 1) * qt(0.975, df = fit$df) * sumCoeff[2, 2]) / 10
x <- diamond$carat
y <- diamond$price
fit <- lm(y ~ x)
newx <- data.frame(x = seq(min(x), max(x), length = 100))
p1 <- data.frame(predict(fit, newdata = newx, interval = ("confidence")))
p2 <- data.frame(predict(fit, newdata = newx, interval = ("prediction")))
p1$interval <- "confidence"
p2$interval <- "prediction"
p1$x <- newx$x
p2$x <- newx$x
dat <- rbind(p1, p2)
names(dat)[1] <- "y"
g <- ggplot(dat, aes(x = x, y = y))
g <- g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g <- g + geom_line()
g <- g + geom_point(data = data.frame(x = x, y = y), aes(x = x, y = y), size = 4)
g
library(datasets)
data(swiss)
require(stats)
require(graphics)
pairs(swiss, panel = panel.smooth, main = "Swiss Data", col = 3 + (swiss$Catholic > 50))
model <- lm(Fertility ~ ., data = swiss)
summary(model)
library(caret)
?kernlab
args(trainControl)
install.packages("ISLR")
library(ISLR)
data("Wage")
data(Wage)
head(wagw)
head(Wage)
summary(Wage)
plot(Wage)
pairs(Wage)
?pairs
pairs(~ age + education + jobclass, data = Wage)
pairs(Wage[, c("age", "education", "jobclass")])
?featurePlot
featurePlot(x = Wage[, c("age", "education", "jobclass")], y = Wage$wage,
plot = "pairs")
featurePlot(x = Wage[, c("age", "education", "jobclass")], y = Wage$wage,
plot = "ellipse")
featurePlot(x = Wage[, c("age", "education", "jobclass")], y = Wage$wage,
plot = "strip")
featurePlot(x = Wage[, c("age", "education", "jobclass")], y = Wage$wage,
plot = "box")
featurePlot(x = Wage[, c("age", "education", "jobclass")], y = Wage$wage,
plot = "pairs")
qplot(age, wage, data = Wage)
qplot(age, wage, colour = jobclass, data = Wage)
p <- qplot(age, wage, colour = education, data = wage)
p <- p + geom_smooth(method = "lm", formula = y ~ x)
p
p <- qplot(age, wage, colour = education, data = wage)
p <- p + geom_smooth(method = "lm", formula = y ~ x)
p
p <- qplot(age, wage, colour = education, data = wage)
p <- p + geom_smooth(method = "lm", formula = y ~ x)
p
p <- qplot(age, wage, colour = education, data = Wage)
p <- p + geom_smooth(method = "lm", formula = y~x)
p
install.packages("twitteR", dependencies = TRUE)
library(twitteR)
library(plyr)
tweets <- searchTwitter("ONGC IS", n = 1000)
tweets <- searchTwitter("ONGC IS", n = 1000)
getTrends("ONGC")
shiny::runApp('DataProducts/Week1')
?colSums
?getMethod
getMethod("mean", "default")
getMethod("mean", "numeric")
getMethod("mean", "numeric")
getMethod("mean", "integer")
getMethod("mean")
getMethod("plot")
showMethods("plot")
showMethods("mean")
showMethods("plot", "default")
showMethods("sum", "default")
showMethods("sum", "numeric")
showMethods("sum")
showMethod("sum")
getMethod("sum")
?showMethods
showMethods("dgamma")
showMethods("lm")
showMethods("predict")
showMethods("dgamma")
showMethods("lm")
showMethods("colSums")
showMethods("predict")
getMethods("dgamaa")
findMethods("dgamma")
findMethods("predict")
findMethods("lm")
findMethods("colSums")
gwtwd()
getwd()
setwd("/Users/Sudhir/Study/R/Python")
ls
dir
dir()
setwd("/Users/Sudhir/Study/R/Python/AIND")
dir()
setwd("/Users/Sudhir/Study/R/Python/AIND/AIND-Isolation-master")
